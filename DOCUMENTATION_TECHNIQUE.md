# üìö Documentation Technique - Splitter

## Architecture g√©n√©rale

### Stack technologique

**Backend :**
- **Runtime** : Node.js (v16+)
- **Framework** : Express.js
- **Traitement CSV** : csv-parser, csv-writer
- **Upload** : Multer
- **Archives** : Archiver
- **S√©curit√©** : Helmet, CORS, express-rate-limit

**Frontend :**
- **Framework** : React 18
- **Upload** : React Dropzone
- **HTTP Client** : Axios
- **Icons** : Lucide React
- **Build** : Create React App

## Structure du code

### Backend (`server.js`)

#### Configuration et middleware

```javascript
// S√©curit√©
app.use(helmet());
app.use(cors());
app.use(express.json({ limit: '10mb' }));

// Rate limiting
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // 100 requ√™tes par IP
});
```

#### Configuration Multer

```javascript
const storage = multer.diskStorage({
  destination: (req, file, cb) => {
    const uploadDir = path.join(__dirname, 'uploads');
    if (!fs.existsSync(uploadDir)) {
      fs.mkdirSync(uploadDir, { recursive: true });
    }
    cb(null, uploadDir);
  },
  filename: (req, file, cb) => {
    const uniqueSuffix = Date.now() + '-' + Math.round(Math.random() * 1E9);
    cb(null, file.fieldname + '-' + uniqueSuffix + '.csv');
  }
});
```

#### Fonctions principales

**`analyzeCsvFile(filePath, hasHeader)`**
- Lit le fichier CSV en streaming
- Compte les lignes
- Extrait les headers si n√©cessaire
- Retourne : `{ totalRows, header, data }`

**`createCsvFile(data, headers, outputPath)`**
- Cr√©e un fichier CSV avec les donn√©es fournies
- Utilise csv-writer pour la g√©n√©ration
- Retourne une Promise

**`cleanupFiles(files)`**
- Supprime les fichiers temporaires
- Utilis√© apr√®s traitement et t√©l√©chargement

### Frontend (`client/src/App.js`)

#### √âtat de l'application

```javascript
const [file, setFile] = useState(null);
const [maxRowsPerFile, setMaxRowsPerFile] = useState(5000);
const [hasHeader, setHasHeader] = useState(true);
const [isProcessing, setIsProcessing] = useState(false);
const [result, setResult] = useState(null);
const [error, setError] = useState(null);
```

#### Gestion des fichiers

**Upload avec React Dropzone :**
```javascript
const { getRootProps, getInputProps, isDragActive } = useDropzone({
  onDrop,
  accept: { 'text/csv': ['.csv'] },
  multiple: false
});
```

**Traitement du d√©coupage :**
```javascript
const handleSplit = async () => {
  const formData = new FormData();
  formData.append('file', file);
  formData.append('maxRowsPerFile', maxRowsPerFile);
  formData.append('hasHeader', hasHeader);
  
  const response = await axios.post('/api/split-csv', formData);
  setResult(response.data);
};
```

## API Endpoints

### POST `/api/split-csv`

**Fonction** : D√©coupe un fichier CSV

**Param√®tres :**
- `file` : Fichier CSV (multipart/form-data)
- `maxRowsPerFile` : Nombre max de lignes par fichier
- `hasHeader` : Boolean (string 'true'/'false')

**R√©ponse succ√®s :**
```json
{
  "success": true,
  "message": "Fichier d√©coup√© avec succ√®s en 3 partie(s)",
  "files": [
    {
      "filename": "data_part1.csv",
      "path": "/path/to/file",
      "rows": 5000
    }
  ],
  "totalRows": 12345,
  "maxRowsPerFile": 5000
}
```

**R√©ponse erreur :**
```json
{
  "error": "Message d'erreur"
}
```

### GET `/api/download/:filename`

**Fonction** : T√©l√©charge un fichier individuel

**Param√®tres :**
- `filename` : Nom du fichier √† t√©l√©charger

**R√©ponse** : Fichier binaire (attachment)

### POST `/api/download-all`

**Fonction** : T√©l√©charge tous les fichiers en ZIP

**Body :**
```json
{
  "files": [
    { "filename": "file1.csv" },
    { "filename": "file2.csv" }
  ]
}
```

**R√©ponse** : Archive ZIP (attachment)

## Algorithmes de d√©coupage

### Avec header

```javascript
// Exemple : 12 345 lignes, limite 5 000
const numberOfFiles = Math.ceil(totalDataRows / maxRows); // 3

for (let i = 0; i < numberOfFiles; i++) {
  const startIndex = i * maxRows;
  const endIndex = Math.min((i + 1) * maxRows, totalDataRows);
  const chunk = dataRows.slice(startIndex, endIndex);
  
  // Chaque fichier contient le header + les donn√©es
  await createCsvFile(chunk, header, outputPath);
}
```

**R√©sultat :**
- `file_part1.csv` : Header + 5 000 lignes
- `file_part2.csv` : Header + 5 000 lignes  
- `file_part3.csv` : Header + 2 344 lignes

### Sans header

M√™me logique mais sans ajout de header dans chaque fichier.

## Gestion des erreurs

### Validation des fichiers

```javascript
// V√©rification du type
if (file.mimetype !== 'text/csv' && !file.originalname.endsWith('.csv')) {
  throw new Error('Seuls les fichiers CSV sont accept√©s');
}

// V√©rification de la taille
if (file.size > 100 * 1024 * 1024) { // 100MB
  throw new Error('Fichier trop volumineux');
}

// V√©rification du contenu
if (hasHeader && analysis.totalRows < 2) {
  throw new Error('Le fichier doit contenir au minimum un header et une ligne de donn√©es');
}
```

### Gestion des erreurs c√¥t√© client

```javascript
try {
  const response = await axios.post('/api/split-csv', formData);
  setResult(response.data);
} catch (err) {
  setError(err.response?.data?.error || 'Une erreur est survenue');
} finally {
  setIsProcessing(false);
}
```

## S√©curit√©

### Middleware de s√©curit√©

```javascript
// Headers de s√©curit√©
app.use(helmet());

// CORS
app.use(cors());

// Rate limiting
app.use('/api/', rateLimit({
  windowMs: 15 * 60 * 1000,
  max: 100
}));
```

### Validation des uploads

```javascript
const upload = multer({
  storage: storage,
  fileFilter: (req, file, cb) => {
    if (file.mimetype === 'text/csv' || file.originalname.endsWith('.csv')) {
      cb(null, true);
    } else {
      cb(new Error('Seuls les fichiers CSV sont accept√©s'), false);
    }
  },
  limits: {
    fileSize: 100 * 1024 * 1024 // 100MB
  }
});
```

### Nettoyage automatique

```javascript
// Apr√®s t√©l√©chargement
setTimeout(() => {
  if (fs.existsSync(filePath)) {
    fs.unlinkSync(filePath);
  }
}, 5000);
```

## Performance

### Optimisations

1. **Streaming** : Lecture des CSV en streaming pour √©viter la surcharge m√©moire
2. **Nettoyage automatique** : Suppression des fichiers temporaires
3. **Rate limiting** : Protection contre les abus
4. **Validation c√¥t√© client** : R√©duction des requ√™tes inutiles

### Limites

- **Taille fichier** : 100MB maximum
- **Rate limiting** : 100 requ√™tes/15min par IP
- **M√©moire** : Traitement en chunks pour √©viter l'overflow

## Tests

### Tests manuels recommand√©s

1. **Fichier avec header**
   - Upload d'un CSV avec en-t√™tes
   - V√©rification de la reproduction des headers
   - Test de t√©l√©chargement individuel et ZIP

2. **Fichier sans header**
   - Upload d'un CSV sans en-t√™tes
   - V√©rification du d√©coupage correct

3. **Fichiers volumineux**
   - Test avec des fichiers proches de 100MB
   - V√©rification des performances

4. **Cas d'erreur**
   - Fichier non-CSV
   - Fichier vide
   - Fichier trop volumineux
   - Param√®tres invalides

### Tests automatis√©s (√† impl√©menter)

```javascript
// Exemple de test avec Jest
describe('CSV Splitter API', () => {
  test('should split CSV file correctly', async () => {
    const response = await request(app)
      .post('/api/split-csv')
      .attach('file', 'test.csv')
      .field('maxRowsPerFile', '1000')
      .field('hasHeader', 'true');
    
    expect(response.status).toBe(200);
    expect(response.body.success).toBe(true);
  });
});
```

## D√©ploiement

### Variables d'environnement

```env
NODE_ENV=production
PORT=5000
```

### Scripts de build

```json
{
  "scripts": {
    "start": "node server.js",
    "dev": "nodemon server.js",
    "build": "cd client && npm run build",
    "heroku-postbuild": "npm run install-client && npm run build"
  }
}
```

### D√©ploiement Heroku

```bash
# Procfile
web: npm start

# D√©ploiement
heroku create
git push heroku main
```

## Maintenance

### Logs

```javascript
// Logs d'erreur
console.error('Erreur lors du traitement:', error);

// Logs de d√©marrage
console.log(`üöÄ Serveur Splitter d√©marr√© sur le port ${PORT}`);
```

### Monitoring

- **Fichiers temporaires** : V√©rification r√©guli√®re du dossier `uploads/`
- **Espace disque** : Surveillance de l'espace disponible
- **Performance** : Monitoring des temps de r√©ponse

### Mises √† jour

1. **D√©pendances** : `npm audit` et `npm update`
2. **S√©curit√©** : Mise √† jour des packages de s√©curit√©
3. **Fonctionnalit√©s** : Ajout de nouvelles options de d√©coupage

---

Cette documentation technique fournit toutes les informations n√©cessaires pour comprendre, maintenir et √©tendre l'application Splitter.
